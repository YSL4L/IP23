{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ff77ba",
   "metadata": {},
   "source": [
    "# Translating with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d003e13",
   "metadata": {},
   "source": [
    "NLTK (Natural Language Toolkit) is a suite of libraries and programs for natural language processing.  NLTK provides tools for tokenization, part-of-speech tagging, stemming, chunking, parsing, and semantic reasoning, among other tasks. It also includes a large collection of corpora, lexicons etc. \n",
    "For this Task relevant is the nltk.corpus package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235ba39b",
   "metadata": {},
   "source": [
    "\n",
    "First, we need to download NLTK and the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfecac4c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltkNote: you may need to restart the kernel to use updated packages.\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34ca986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Code will download all the data from nltk and open a window in which you can see the download progress. \n",
    "nltk.download() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdeb9e2",
   "metadata": {},
   "source": [
    "# Translating a file with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02476d3c",
   "metadata": {},
   "source": [
    "This code imports the NLTK library and the comtrans module from NLTK, and loads the bilingual English-french corpus. It then creates a translation dictionary using the words and mots from the corpus. It then opens an English file, tokenizes it, and translates it using the translation dictionary. Finally, it writes the German (in this case french) version of the document to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ef8b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import comtrans\n",
    "\n",
    "# load the english-french corpus\n",
    "bilingual_corpus = comtrans.aligned_sents('alignment-en-fr.txt')\n",
    "\n",
    "# create a translation dictionary\n",
    "trans_dict = dict()\n",
    "for sent in english_german:\n",
    "    for english, german in zip(sent.words, sent.mots):\n",
    "        # add the english-german translation to the dictionary\n",
    "        trans_dict[english] = german\n",
    "\n",
    "# open and read the english file\n",
    "with open(\"ice_man.txt\", encoding='utf-8') as f:\n",
    "    english_file = f.read()\n",
    "\n",
    "# tokenize the english file\n",
    "english_tokens = nltk.word_tokenize(english_file)\n",
    "\n",
    "# translate the english file\n",
    "german_file = \"\"\n",
    "for token in english_tokens:\n",
    "    if token in trans_dict:\n",
    "        german_file += trans_dict[token] + \" \"\n",
    "    else:\n",
    "        german_file += token + \" \"\n",
    "\n",
    "# write the german file\n",
    "with open(\"german_file.txt\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(german_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this, we can only translate from english to french"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1582e8e",
   "metadata": {},
   "source": [
    "# Python \"translate\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b4b80a",
   "metadata": {},
   "source": [
    "An other option to translate is the python \"translate' libary. For this we need to install and import translate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f8a73a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting translate\n",
      "  Downloading translate-3.6.1-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from translate) (2.27.1)\n",
      "Requirement already satisfied: click in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from translate) (8.0.4)\n",
      "Collecting libretranslatepy==2.1.1\n",
      "  Downloading libretranslatepy-2.1.1-py3-none-any.whl (3.2 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from translate) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from click->translate) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from requests->translate) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from requests->translate) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from requests->translate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hanho\\anaconda3\\lib\\site-packages (from requests->translate) (2.10)\n",
      "Installing collected packages: libretranslatepy, translate\n",
      "Successfully installed libretranslatepy-2.1.1 translate-3.6.1Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install translate \n",
    "import translate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5da5c290",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\translate\\translate.py:45\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m text_list \u001b[38;5;241m=\u001b[39m wrap(text, TRANSLATION_API_MAX_LENGHT, replace_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_wraped\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text_wraped \u001b[38;5;129;01min\u001b[39;00m text_list)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\translate\\providers\\mymemory_translated.py:49\u001b[0m, in \u001b[0;36mMyMemoryProvider.get_translation\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     48\u001b[0m matches \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 49\u001b[0m next_best_match \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m next_best_match[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranslation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [142]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#with this code we translate from english to german\u001b[39;00m\n\u001b[0;32m      6\u001b[0m translator \u001b[38;5;241m=\u001b[39m translate\u001b[38;5;241m.\u001b[39mTranslator(from_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m,to_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgerman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m translation \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#now we create a new file called \"output.txt\" with the german translation in it.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\translate\\translate.py:45\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[0;32m     44\u001b[0m text_list \u001b[38;5;241m=\u001b[39m wrap(text, TRANSLATION_API_MAX_LENGHT, replace_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_wraped\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_wraped\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "#again we need to read the file\n",
    "with open('ice_man.txt', 'r', encoding='utf-8') as f: \n",
    "    text = f.read() \n",
    "    \n",
    "#with this code we translate from english to german\n",
    "translator = translate.Translator(from_lang=\"english\",to_lang=\"german\")\n",
    "translation = translator.translate(text) \n",
    "\n",
    "#now we create a new file called \"output.txt\" with the german translation in it.\n",
    "with open('output.txt', 'w', encoding='utf-8') as f: \n",
    "    f.write(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e297e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!#With this option we can only translate texts that have less than 500 chars!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c2c9e",
   "metadata": {},
   "source": [
    "# Googletrans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac9db6",
   "metadata": {},
   "source": [
    "We can also use googletrans to translate in python (max. 15.000 chars) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f6051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install googletrans==3.1.0a0\n",
    "from googletrans import Translator\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6d84cb17",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [133]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      5\u001b[0m translator \u001b[38;5;241m=\u001b[39m Translator()\n\u001b[1;32m----> 6\u001b[0m translation \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mde\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(translation\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle.txt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\client.py:182\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    181\u001b[0m origin \u001b[38;5;241m=\u001b[39m text\n\u001b[1;32m--> 182\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# this code will be updated when the format is changed.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\client.py:78\u001b[0m, in \u001b[0;36mTranslator._translate\u001b[1;34m(self, text, dest, src, override)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_translate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, dest, src, override):\n\u001b[1;32m---> 78\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_acquirer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     params \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mbuild_params(query\u001b[38;5;241m=\u001b[39mtext, src\u001b[38;5;241m=\u001b[39msrc, dest\u001b[38;5;241m=\u001b[39mdest,\n\u001b[0;32m     80\u001b[0m                                 token\u001b[38;5;241m=\u001b[39mtoken, override\u001b[38;5;241m=\u001b[39moverride)\n\u001b[0;32m     82\u001b[0m     url \u001b[38;5;241m=\u001b[39m urls\u001b[38;5;241m.\u001b[39mTRANSLATE\u001b[38;5;241m.\u001b[39mformat(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pick_service_url())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\gtoken.py:194\u001b[0m, in \u001b[0;36mTokenAcquirer.do\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     tk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire(text)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tk\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\googletrans\\gtoken.py:62\u001b[0m, in \u001b[0;36mTokenAcquirer._update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# this will be the same as python code after stripping out a reserved word 'var'\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRE_TKK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# unescape special ascii characters such like a \\x3d(=)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m code \u001b[38;5;241m=\u001b[39m code\u001b[38;5;241m.\u001b[39mencode()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode-escape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "with open('ice_man.txt', 'r', encoding='utf-8') as f: \n",
    "    text = f.read()\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "translation = translator.translate(text,dest='de') \n",
    "\n",
    "print(translation.text)\n",
    "with open ('google.txt','w') as f:\n",
    "    f.write(translation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca88ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I get a AttributeError: 'NoneType' object has no attribute 'group'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a06c4",
   "metadata": {},
   "source": [
    "# Calculating the sentiment with Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "31992074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of English File:\n",
      "Sentiment(polarity=0.08925143936379887, subjectivity=0.4623254814266053)\n",
      "Sentiment of German File:\n",
      "Sentiment(polarity=0.06477272727272726, subjectivity=0.5340909090909091)\n",
      "The sentiment of the English and German files differ.\n"
     ]
    }
   ],
   "source": [
    "#This code imports the TextBlob module from textblob library to perform sentiment analysis. \n",
    "from textblob import TextBlob \n",
    "\n",
    "#reads the file and assigns the content to the variable 'text_en'.\n",
    "with open(\"ice_man.txt\") as f: \n",
    "    text_en = f.read()\n",
    "blob_en = TextBlob(text_en) #creates a TextBlob object with text_en. \n",
    "\n",
    "print(\"Sentiment of English File:\") #prints out the sentiment of the file.\n",
    "print(blob_en.sentiment)\n",
    "\n",
    "#reads the german_file and assigns the content to the variable 'text_de'\n",
    "with open(\"german_file.txt\") as f: \n",
    "    text_de = f.read()\n",
    "blob_de = TextBlob(text_de) #creates a TextBlob object with text_de\n",
    "\n",
    "print(\"Sentiment of German File:\") \n",
    "print(blob_de.sentiment)\n",
    "if blob_en.sentiment != blob_de.sentiment: #checks if the sentiment of the English and German files are the same.\n",
    "    print(\"The sentiment of the English and German files differ.\")\n",
    "else:\n",
    "    print(\"The sentiment of the English and German files are the same.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ed706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc19af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
